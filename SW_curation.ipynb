{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d834d8-8224-4d81-99cf-3ed728965ef3",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2fe73e-618d-473e-acb9-544d0c6aea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "from RISparser import readris\n",
    "import nbib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9aefe6-b4bc-4f6c-9d51-15929b4e2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc9e24-3a16-47ed-a6ce-f39d6a94a4aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create formatted query\n",
    "\n",
    "This section takes the journal list and produces a formatted query to search the three major databases.  The procedure involves pasting search operators around the journal names and concatenating everything into a single query that can be copied from the notebook and pasted directly into the search bar.  All searches were performed on September 22, 2021.  \n",
    "\n",
    "```\n",
    "df = pd.read_csv('/Users/brian/Coding/COVID-research/data/Journals.csv')\n",
    "df = df['Journals'].tolist()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916018b9-ff7f-4d6e-aa90-f64b2c430199",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _Web of science_\n",
    "The Web of Science (WoS) was specified to capture all records from January 1, 2014 through September 22, 2021.  The exports were made to include all the cited references to each article.  By doing so, the batch limit for export was limited to 500 records.  The records were downloaded as tab-demilited files. The files were then combined and processed using this notebook.   \n",
    "\n",
    "```\n",
    "web_of_science = ' OR '.join(df)\n",
    "web_of_science = \"SO = \" + \"(\" + web_of_science + \")\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be78af-622d-40e1-a774-a1ab21406bfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _PubMed_ \n",
    "PubMed contains only a subset of social work journals.  No date limits were put on the search.  The search produced 10,033 articles, going back to the 1970's.  The maximum number of records that can be extracted is 10,000.  Thus, the search results were sorted in the web interface from newest to oldest, and then the extraction was made.  Thus, 33 articles were not retaiend, but these are the oldest records that will not be used in our current work.  Additonally the current cleaning script also excludes all articles publised before 2014.  The extract from PubMed was in a standard RIS format (\\*.nbib).  This file was imported into Zotero, exported as a csv file, and processed with this notebook.  \n",
    "\n",
    "```\n",
    "pub_med = pub_med = [\"(\\\"\" + k +\"\\\"[Journal])\" for k in df]\n",
    "pub_med = ' OR '.join(pub_med)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9538771-18ff-4fba-acb1-397b6f31efc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _EBSCOhost_\n",
    "\n",
    "Search was performed on September 22, 2021 using the followign search, capturing everything published since 2014 (inclusive).  For this pull, I extracted article records with all the cited references.  In doing so, the extract batch limit was 500, whereas the article records without the cited references allows for batches of 1,000.  The files were saved in a RIS format, which is used by bibliogrphy managers, like Zotero and EndNote.  To process these files, we used a Python module called `RISparsers`.  This converted the files to a Pandas dataframe, which was then prepared for analysis.   \n",
    "\n",
    "* Social Work Abstracts\n",
    "* APA PsycInfo\n",
    "* Abstracts in Social Gerontology;\n",
    "* Child Development & Adolescent Studies;\n",
    "* Family Studies Abstracts;\n",
    "* Political Science Complete;\n",
    "* Violence & Abuse Abstracts;\n",
    "* Women's Studies International\n",
    "\n",
    "```\n",
    "ebsco = [\"SO \" + \"\\\"\" + k + \"\\\"\" +  \" OR\" for k in df]\n",
    "ebsco = \" \".join(ebsco) \n",
    "ebsco = re.sub(\"OR$\", \"\", ebsco)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecd4a9-de9f-4fbe-a041-39663cb70348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "This section prepares the data for cleaning.  Each "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60d3bf-5e50-4bb8-ab90-5ea3e3b61f96",
   "metadata": {},
   "source": [
    "### Prepare _Web of Science_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa11c484-9210-4439-aa66-91bac1052fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Coding/Data/SocialWorkJournals/WoS\n"
     ]
    }
   ],
   "source": [
    "# Read and combine the WoS data files\n",
    "%cd /Users/brian/Coding/Data/SocialWorkJournals/WoS\n",
    "wos = glob('save*.txt')\n",
    "\n",
    "wos = pd.DataFrame()\n",
    "\n",
    "for f in glob(\"save*.txt\"):\n",
    "    holder = pd.read_table(f, sep = \"\\t\",\\\n",
    "                        engine = \"python\",\\\n",
    "                        header=0,\\\n",
    "                        usecols=([0,4,7,8,11,12,18,19,20,21,22,23,\\\n",
    "                                 25,26,27,28,29,31,34,40,\\\n",
    "                                 41,42,43,55,60,61,62,65]),\\\n",
    "                        parse_dates = True,\\\n",
    "                        infer_datetime_format = True,\\\n",
    "                        quoting=3,\n",
    "                        #quotechar='\"',\n",
    "                        #quotechar=\"\\\"\") \n",
    "                        on_bad_lines = \"skip\")\n",
    "    wos = wos.append(holder,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849774d1-4c7b-4ce3-a697-3738d5bf6ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The columns are incorrectly named in the file.  This procedure renames the \n",
    "# column retrieved.  This mistake can be observed by looking at the raw\n",
    "# text files.  \n",
    "wos.columns = ['authors', 'author_full_name', 'title', 'journal', 'language',\n",
    "       'document_type', 'keywords_au', 'keywords_journal', 'abstract',\n",
    "       'author_address', 'corresponding_author', 'email_address', 'ID_ORCID',\n",
    "       'funding_agency', 'funding_text', 'cited_references',\n",
    "       'cited_reference_count', 'total_times_cited', 'publisher',\n",
    "       'journal_abbv', 'journal_abbv_dot', 'publication_date',\n",
    "       'publication_year', 'early_access_date', 'id_database', 'ID_PubMed',\n",
    "       'open_access_indicator', 'date_of_data_pull']\n",
    "\n",
    "# Data identifier\n",
    "wos['data_source'] = \"wos\"\n",
    "\n",
    "# Reduce data to key variables\n",
    "wos = wos[['authors', 'title', 'journal', 'document_type',\\\n",
    "           'abstract', 'publication_year', 'early_access_date',\\\n",
    "           'data_source', 'publication_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6b33ef-2443-496d-8824-dd5b0f95890b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract year digits from string\n",
    "wos['early_access_date'] = wos['early_access_date'].str.extract('(\\d+)').astype(int, errors = 'ignore')\n",
    "wos['publication_year'] = wos['publication_year'].astype(int, errors = 'ignore')\n",
    "\n",
    "# Address missing date data by using early access date when publication year is missing\n",
    "wos['publication_year'] = np.where(wos['publication_year'].isnull(),\\\n",
    "                                   wos['early_access_date'],\\\n",
    "                                   wos['publication_year'])\n",
    "\n",
    "# Filter to 2014 and later. Convert to integer and then filter\n",
    "wos['publication_year'] = wos['publication_year'].astype(int)\n",
    "filter_date = wos['publication_year'] > 2013\n",
    "wos = wos[filter_date]\n",
    "\n",
    "\n",
    "filter_doc_types = wos['document_type'].str.contains('article|^review$', case = False) \n",
    "wos = wos[filter_doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c009683a-15db-40eb-83f1-ceaf93744664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wos.drop(columns = ['early_access_date', 'document_type', 'publication_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20bdb68a-af03-4274-8fea-ea430fd7ccbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authors             object\n",
       "title               object\n",
       "journal             object\n",
       "abstract            object\n",
       "publication_year     int64\n",
       "data_source         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67258bfd-226c-4c4e-9c1a-4f25d0a02caf",
   "metadata": {},
   "source": [
    "### Prepare _PubMed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bba94e-2dfe-40ec-9ce6-cb3e27fb58d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Coding/Data/SocialWorkJournals/PubMed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 39)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd '/Users/brian/Coding/Data/SocialWorkJournals/PubMed'\n",
    "\n",
    "refs = nbib.read_file('/Users/brian/Coding/Data/SocialWorkJournals/PubMed/pubmed_2021_09_22.nbib')\n",
    "pubmed = pd.DataFrame.from_dict(refs)\n",
    "pubmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32197a86-44a8-4bcd-8377-9786f1006dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pubmed_id', 'citation_owner', 'nlm_status', 'last_revision_date',\n",
       "       'print_issn', 'electronic_issn', 'linking_issn', 'publication_date',\n",
       "       'title', 'abstract', 'copyright', 'authors', 'language',\n",
       "       'publication_types', 'electronic_publication_date',\n",
       "       'journal_abbreviated', 'journal', 'nlm_journal_id', 'pmcid', 'keywords',\n",
       "       'conflict_of_interest', 'received_time', 'revised_time',\n",
       "       'accepted_time', 'entrez_time', 'pubmed_time', 'medline_time', 'pii',\n",
       "       'doi', 'publication_status', 'pages', 'place_of_publication',\n",
       "       'journal_volume', 'journal_issue', 'grants', 'pmc-release_time',\n",
       "       'descriptors', 'secondary_source', 'corporate_author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa61b1d-905e-47be-8ea1-65087207d485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns by location\n",
    "pubmed = pubmed.iloc[ : , [7,8,9,11,13, 16]]\n",
    "\n",
    "# Rename columns\n",
    "pubmed.rename(columns = {'publication_types':'document_type'}, inplace=True)\n",
    "\n",
    "# Create data identifier\n",
    "pubmed['data_source'] = 'pubmed'\n",
    "\n",
    "# Filter by date\n",
    "pubmed = pubmed[pubmed['publication_date'] > \"2014-01-01\"]\n",
    "\n",
    "# Create a publication year variable through string extraction\n",
    "pubmed['publication_year'] = pubmed['publication_date'].str.extract('(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab391220-2256-44e4-9a58-a9f290dfd091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document types are packed in a list.  The first element indicates 'journal article'\n",
    "# This procedures unpacks the list into a DataFrame of 4 columns. \n",
    "pubmed_docs = pubmed['document_type'].apply(pd.Series)\n",
    "\n",
    "# Rename the first column of interest\n",
    "pubmed_docs.rename(columns = {0:'document_type_new'}, inplace=True)\n",
    "\n",
    "# Drop the other columns\n",
    "pubmed_docs.drop(columns = [1,2,3], axis = 1, inplace=True)\n",
    "\n",
    "# Concatenate document type variable with the pubmed data\n",
    "pubmed = pd.concat([pubmed, pubmed_docs], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e65293-3f5e-4e7d-b19e-7e9c093d85d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in empty document type with \"inspect\" so it isn't dropped\n",
    "pubmed['document_type'] = np.where(pubmed['document_type_new'].isnull(),\\\n",
    "                                   \"Inspect\",\\\n",
    "                                   pubmed['document_type_new'])\n",
    "\n",
    "# Create a filter of document types for inspection\n",
    "filter_doc_type = pubmed['document_type'].str.contains('article|study|report|inspect', case=False)\n",
    "\n",
    "# Apply the filter to the data set\n",
    "pubmed = pubmed[filter_doc_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75cd04f9-9967-41a7-bf5e-ecc1d4760a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up the data set by dropping unnecessary columns\n",
    "pubmed.drop(columns = ['document_type', 'document_type_new', 'publication_date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb1854-137a-4b77-9cf4-112d711a18f7",
   "metadata": {},
   "source": [
    "### Prepare _EBSCOhost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a39c89-fb4d-4a36-9dca-666de34921de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Coding/Data/SocialWorkJournals/EBSCO\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/brian/Coding/Data/SocialWorkJournals/EBSCO/'\n",
    "files = glob('*.ris')\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as bibliography_file:\n",
    "        entries = readris(bibliography_file)#, skip_missing_tags=True)\n",
    "\t    ## create a dataframe once per loop, only\n",
    "        df = pd.DataFrame.from_dict(entries)\n",
    "        ## only use pandas API methods (e.g. `drop`) to operate on entries in bulk\n",
    "        if 'unknown_tag' in df.columns:\n",
    "            df = df.drop('unknown_tag', axis=1) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "        df_list.append(df)\n",
    "\n",
    "# concatenate data frames once, instead of n times inside a loop\n",
    "ebsco = pd.concat(df_list) # https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d4be13-5aba-45dc-abfa-58c47e283eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_of_reference\n",
      "authors\n",
      "primary_title\n",
      "journal_name\n",
      "alternate_title3\n",
      "publication_year\n",
      "volume\n",
      "number\n",
      "type_of_work\n",
      "start_page\n",
      "end_page\n",
      "issn\n",
      "abstract\n",
      "keywords\n",
      "notes\n",
      "url\n",
      "database_provider\n",
      "name_of_database\n",
      "id\n",
      "year\n",
      "place_published\n",
      "publisher\n",
      "language\n",
      "accession_number\n",
      "alternate_title2\n",
      "author_address\n",
      "doi\n",
      "secondary_title\n",
      "tertiary_title\n",
      "title\n",
      "access_date\n",
      "translated_title\n"
     ]
    }
   ],
   "source": [
    "print(*ebsco.columns, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea25c70-e60e-4569-8484-0e43467b8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest by integer location\n",
    "ebsco = ebsco.iloc[ :,[1,2,3,5,8,12, 19]]\n",
    "\n",
    "# Rename columns\n",
    "ebsco.columns = ['authors', 'title', 'journal', 'publication_year',\\\n",
    "                 'document_type', 'abstract', 'year']\n",
    "\n",
    "# Add data_source identifier\n",
    "ebsco['data_source'] = 'ebsco'\n",
    "\n",
    "# # Drop duplicates\n",
    "# ebsco.drop_duplicates(subset = 'title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019aae09-9ff7-4136-b737-b93562e041ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year variable from a string\n",
    "ebsco['year'] = ebsco['year'].str[:4]\n",
    "ebsco['publication_year'] = ebsco['publication_year'].str[:4]\n",
    "\n",
    "# Use two different date variables to address missing publication year\n",
    "ebsco['publication_year'] = np.where(ebsco['publication_year'].isnull(), ebsco['year'], ebsco['publication_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e2d9f0-0930-4742-9710-4482dcbfafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab document types of interest and those with missing information. These\n",
    "# are retained for inspection\n",
    "ebsco['document_type'] = np.where(ebsco['document_type'].isnull(), \"inspect\", ebsco['document_type'])\n",
    "filter_doc_types = ebsco['document_type'].str.contains('article|case study|opinion|inspect', case = False) \n",
    "ebsco = ebsco[filter_doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f1805f5-1135-476a-a12a-37d66bbe9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup of data\n",
    "ebsco.drop(columns = ['year', 'document_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4f2d8-2128-479f-9e38-aa594d5ca292",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the final database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f1eb659-a675-449f-a7f9-5e23d52773f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in order of quality\n",
    "final = pd.concat([ebsco, wos, pubmed])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b98855-7b46-45f0-889d-4ca634deb1e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Duplicate and missing values\n",
    "\n",
    "This procedure is to prepare the data files for text processing.  This initial step involves the following steops:\n",
    "\n",
    "* Drop duplicate titles and abstracts following the merge of the three data sources;\n",
    "* Drop entries in which either a title or abstract is missing;\n",
    "* Strip leading and trailing white space characters\n",
    "* Create a pre-cleaning data file to allow comparisons of the data after the database has been cleaned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94599ae9-3a65-482a-8ffa-73e303e9b7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authors             object\n",
       "title               object\n",
       "journal             object\n",
       "publication_year    object\n",
       "abstract            object\n",
       "data_source         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5750dab3-ac3d-44c3-9c2c-8bf23837013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up abstracts by first dropping duplicates and then missing abstracts\n",
    "final['abstract'] = final['abstract'].astype(str).str.strip()\n",
    "final.drop_duplicates(subset = ['abstract'], inplace=True)\n",
    "final.dropna(subset = ['abstract'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecf64d6c-0a6b-4242-a4e0-8cabf040ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57030, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c65019d-90ab-48e7-b630-c11424549cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up titles by first dropping duplicates and then missing abstracts\n",
    "final['title'] = final['title'].str.replace(\"\\.$\", \"\", regex=True)\n",
    "final['title_lower'] = final['title'].str.lower().str.strip().str.replace('[^\\w\\s]','', regex=True)\n",
    "final = final.drop_duplicates(subset = ['title_lower'], keep = \"first\")\n",
    "final = final.dropna(subset = ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b1fd8a7-5025-476d-ac5a-9288f07a8812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    practice in a pandemic school social workers a...\n",
       "1    maternal adverse childhood experience exposure...\n",
       "2    working with nonoffending caregivers of childr...\n",
       "3    mental health among black youth experiencing s...\n",
       "4    a comparison of coping strategies among homele...\n",
       "Name: title_lower, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['title_lower'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c212f7d9-43c1-4ee7-9fa2-6de9813fb9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Coding/Data/SocialWorkJournals\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/brian/Coding/Data/SocialWorkJournals/'\n",
    "final.to_csv('journals_pre_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dec3c7-88d7-4c91-9027-e528a339d179",
   "metadata": {},
   "source": [
    "### Text process journal titles\n",
    "\n",
    "This section processes the journal titles.  This involves hardcoding the exclusion of journal titles that were captured during our search.  Additionally, as some journals come from different databases, we also observe non-standardized spellings.  The following procedures resolve this problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f3ba00-a099-4a44-a55b-d6d43d82c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove journals through hard-coded problems\n",
    "\n",
    "final['journal'] = final['journal'].str.lower()\n",
    "final.dropna(subset = ['journal'], inplace=True)\n",
    "\n",
    "# Standardize journal titles\n",
    "\n",
    "# Remove leading and trailing white space\n",
    "final['journal'] = final['journal'].str.strip()\n",
    "\n",
    "# Standardize titles by converting \"and\" to \"&\"\n",
    "final['journal'] = final['journal'].str.replace(\"\\sand\\s\", \" & \", regex=True)\n",
    "\n",
    "# Remove parantheses\n",
    "final['journal'] = final['journal'].str.replace(\"\\(.*\\)\", \"\", regex=True).str.strip()\n",
    "\n",
    "# Remove colon and everything that follows\n",
    "final['journal'] = final['journal'].str.replace(\"\\:.*\", \"\", regex = True)\n",
    "\n",
    "# Remove 'the' from title\n",
    "final['journal'] = final['journal'].str.replace(\"^the\", \"\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46dd4d9b-0c56-4f0e-90da-2a6a6cc35b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_terms = ['profile',\\\n",
    "                'nurses',\\\n",
    "                'social development issues',\\\n",
    "                'social development in africa',\\\n",
    "                'teachers\\'s professional development',\\\n",
    "                'visual impairment',\\\n",
    "                'clinical psychology',\\\n",
    "                'humanities',\\\n",
    "                'clinical psychology',\\\n",
    "                'profile',\\\n",
    "                'professional development in education',\\\n",
    "                'teachers',\\\n",
    "                'professional development',\\\n",
    "                'rajagiri',\\\n",
    "                'indigenous social development',\\\n",
    "                'economic & social development',\\\n",
    "                'homeless families',\\\n",
    "                '^social development$',\\\n",
    "                'journal of human services',\\\n",
    "                '^review',\\\n",
    "                'Global Social Welfare',\\\n",
    "                'Journal of Community Practice',\\\n",
    "                'Journal of Social Welfare & Family Law',\\\n",
    "                'Journal of Technology in Human Services',\\\n",
    "                'Journal of Applied Social Science',\\\n",
    "                'Journal of Gay & Lesbian Social Services',\\\n",
    "                'Journal of Health & Human Services Administration',\\\n",
    "                'Scientific Annals of',\\\n",
    "                'Social Welfare Interdisciplinary Approach',\\\n",
    "                'Social Work with People with Learning Difficulties',\\\n",
    "                'Revista',\\\n",
    "                'Social intervention',\\\n",
    "                'Portuguese Journal of Behavioral'\n",
    "                ]\n",
    "\n",
    "final = final[~final['journal'].str.contains('|'.join(filter_terms), regex=True, case=False)]\n",
    "final['journal'] = final['journal'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf8eb9fa-65be-4575-9f34-3984707e6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['families in society' 'journal of social work education'\n",
      " 'journal of social work practice' 'social work & christianity'\n",
      " 'child & adolescent social work journal' 'social work education'\n",
      " 'social work research' 'health & social work' 'social work'\n",
      " 'children & schools' 'clinical social work journal'\n",
      " 'european journal of social work' 'social work in public health'\n",
      " 'journal of baccalaureate social work' 'journal of family social work'\n",
      " 'journal of human behavior in the social environment'\n",
      " 'child & family social work' 'british journal of social work'\n",
      " 'social work in health care' 'journal of teaching in social work'\n",
      " 'journal of religion & spirituality in social work'\n",
      " 'human service organizations'\n",
      " 'journal of social work practice in the addictions'\n",
      " 'social work in mental health' 'journal of gerontological social work'\n",
      " 'journal of evidence-based social work' 'affilia'\n",
      " 'international journal of social welfare'\n",
      " 'asian social work & policy review' 'social service review'\n",
      " 'australian social work' 'journal of sociology & social welfare'\n",
      " 'journal of hiv/aids & social services'\n",
      " 'research on social work practice' 'ethics & social welfare'\n",
      " 'international social work' 'reflections'\n",
      " 'journal of progressive human services' 'journal of forensic social work'\n",
      " 'social work with groups' 'psychoanalytic social work'\n",
      " 'canadian social work review' 'smith college studies in social work'\n",
      " 'qualitative social work'\n",
      " 'journal of social work in end-of-life & palliative care'\n",
      " 'journal of social work in disability & rehabilitation'\n",
      " 'journal of psychosocial oncology' 'journal of social work'\n",
      " 'school social work journal'\n",
      " 'journal of the society for social work & research'\n",
      " 'aotearoa new zealand social work'\n",
      " 'ljetopis socijalnog rada / annual of social work'\n",
      " 'czech & slovak social work / sociální práce / sociálna práca'\n",
      " 'journal of society & social work' 'journal of social service research'\n",
      " 'journal of social work values & ethics'\n",
      " 'hong kong journal of social work' 'social work & social sciences review'\n",
      " 'asia pacific journal of social work & development'\n",
      " 'china journal of social work' 'social work / maatskaplike werk'\n",
      " 'advances in social work' 'social work forum / fórum sociální práce'\n",
      " 'journal of ethnic & cultural diversity in social work' 'practice'\n",
      " 'indian journal of social work'\n",
      " 'southern african journal of social work & social development'\n",
      " 'indian journal of psychiatric social work'\n",
      " 'advances in social work & welfare education'\n",
      " 'trabajo social global - global social work'\n",
      " 'journal of nephrology social work' 'human service organizations '\n",
      " 'journal of human rights & social work' 'critical & radical social work'\n",
      " 'social work & sociology']\n"
     ]
    }
   ],
   "source": [
    "print(final.journal.unique(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4e3dbb2-5948-4358-8504-11e9e746609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 'Journal of religion: social thought' has a transposed version, 'Social thought: journal of religion'\n",
    "final['journal'] = final['journal'].str.replace(\"social thought\", \"\", regex=True)\n",
    "\n",
    "# Fix journal title name before cleaning\n",
    "final['journal'] = final['journal'].str.replace(\"oncology research & practice\", \"oncology\")\n",
    "\n",
    "#Remove \"& development\" from New Zealand journal\n",
    "final['journal'] = final['journal'].str.replace(\"zealand social work review\", \"zealand social work\")\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"^canadian social work$\",\\\n",
    "                                                \"canadian social work review\", regex=True)\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"management leadership & governance\",\\\n",
    "                                                \"\", regex=True)\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"hiv-aids\",\\\n",
    "                                                \"hiv/aids\", regex=True)\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"psychoanalytical\",\\\n",
    "                                                \"psychoanalytic\", regex=True)\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"work-maatskaplike\",\\\n",
    "                                                \"work / maatskaplike\", regex=True)\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"global-global\",\\\n",
    "                                                \"global - global\", regex=True)\n",
    "\n",
    "\n",
    "final['journal'] = final['journal'].str.replace(\"evidence-informed\", \"evidence-based\", regex=True)\n",
    "\n",
    "final = final[~final['journal'].str.contains('^social development', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e93d473c-4cfa-4e8a-b6c9-f729d7bc513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional standardization using generalizable (not hard-coded) solutions. \n",
    "\n",
    "\n",
    "\n",
    "# Drop all entries with NA or empty cells\n",
    "final = final.dropna(subset=['journal'])\n",
    "final = final[final['journal'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87efb18d-3f3a-4a23-99bf-2855bf81cb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21592, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00ed76-d8c8-4a9e-8c07-3fbddbfe3d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean abstracts\n",
    "\n",
    "Approximately 11k entries have an unspecified `document_type`.  These are limited to the EBSCO data source.  Thus, these missing values on `document_type` are replaced by _Article_, and then inspection is performed to remove editorials, book reviews, and other scientific communications. Note that \"case study.\" is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7110e-02b5-4db8-aafe-d618d3947cbf",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "Exclude from abstract:  ```[ABSTRACT FROM AUTHOR]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62e49e6b-a299-4341-86f1-60249287b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract filter terms\n",
    "filter_terms = ['an introduction to',\\\n",
    "                'erratum',\\\n",
    "                'correction notice',\\\n",
    "                'editor',\\\n",
    "                'book review',\\\n",
    "                'reviews the book',\\\n",
    "                'review of the book',\\\n",
    "                'obituary',\\\n",
    "                'commentary',\\\n",
    "                'a correction',\\\n",
    "                'reports an error',\\\n",
    "                'reviews the book',\\\n",
    "                'letter'\n",
    "               ]\n",
    "\n",
    "#filter_abstracts = final['abstract'].str.lower().str.contains(filter_terms)\n",
    "final = final[~final['abstract'].str.contains('|'.join(filter_terms),\\\n",
    "                                              regex=True, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85387d3a-b106-4d83-9d42-765fd9f628c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20206, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20927d18-17c8-4312-b91b-d7f5dac3e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter abstracts < 100 characters\n",
    "final['abstract_length'] = final['abstract'].str.len()\n",
    "final = final[final['abstract_length'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61c5e061-0857-493a-a5b1-172f828373cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude book reviews\n",
    "# Note:  three records exist for an article with \"Michael Gove\" in the title.  \n",
    "# These records are temporarily excluded and single record will be added.  \n",
    "\n",
    "filter_terms = ['editor', 'letter', 'comment', 'michael gove']\n",
    "\n",
    "final = final[~final['title'].str.contains('|'.join(filter_terms), regex=True, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a96d65d5-5b20-4367-85b6-b928de1bc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Coding/Data/SocialWorkJournals\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/brian/Coding/Data/SocialWorkJournals/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1a84808-229e-4b91-88c4-ed247963ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('SocialWork_2014_2021.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
